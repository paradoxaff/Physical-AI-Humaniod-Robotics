"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[595],{5244:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"modules/module-02-gazebo-unity/sim2real-transfer","title":"Chapter 3 - Sim2Real Transfer","description":"Learning Objectives","source":"@site/docs/modules/module-02-gazebo-unity/sim2real-transfer.mdx","sourceDirName":"modules/module-02-gazebo-unity","slug":"/modules/module-02-gazebo-unity/sim2real-transfer","permalink":"/docs/modules/module-02-gazebo-unity/sim2real-transfer","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/modules/module-02-gazebo-unity/sim2real-transfer.mdx","tags":[],"version":"current","frontMatter":{"title":"Chapter 3 - Sim2Real Transfer","sidebar_label":"Sim2Real Transfer"},"sidebar":"tutorialSidebar","previous":{"title":"Physics-Based Simulation","permalink":"/docs/modules/module-02-gazebo-unity/physics-based-simulation"},"next":{"title":"Unity Simulation","permalink":"/docs/modules/module-02-gazebo-unity/unity-simulation"}}');var a=i(4848),o=i(8453);const r={title:"Chapter 3 - Sim2Real Transfer",sidebar_label:"Sim2Real Transfer"},s="Chapter 3: Sim2Real Transfer",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Physical AI Concept",id:"physical-ai-concept",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Sim2Real Transfer Architecture",id:"sim2real-transfer-architecture",level:3},{value:"Domain Randomization Pipeline",id:"domain-randomization-pipeline",level:3},{value:"Tools &amp; Software",id:"tools--software",level:2},{value:"Code / Configuration Examples",id:"code--configuration-examples",level:2},{value:"System Identification for Dynamics Modeling",id:"system-identification-for-dynamics-modeling",level:3},{value:"Domain Randomization Environment",id:"domain-randomization-environment",level:3},{value:"Robust Control with Adaptation",id:"robust-control-with-adaptation",level:3},{value:"Practical Lab / Simulation",id:"practical-lab--simulation",level:2},{value:"Lab Exercise 1: Reality Gap Analysis",id:"lab-exercise-1-reality-gap-analysis",level:3},{value:"Lab Exercise 2: Domain Randomization Implementation",id:"lab-exercise-2-domain-randomization-implementation",level:3},{value:"Lab Exercise 3: System Identification",id:"lab-exercise-3-system-identification",level:3},{value:"Lab Exercise 4: Adaptive Control Design",id:"lab-exercise-4-adaptive-control-design",level:3},{value:"Lab Exercise 5: Transfer Validation",id:"lab-exercise-5-transfer-validation",level:3},{value:"Lab Exercise 6: Curriculum Learning for Transfer",id:"lab-exercise-6-curriculum-learning-for-transfer",level:3},{value:"Real-World Mapping",id:"real-world-mapping",level:2},{value:"Industrial Applications",id:"industrial-applications",level:3},{value:"Research Applications",id:"research-applications",level:3},{value:"Key Success Factors",id:"key-success-factors",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"chapter-3-sim2real-transfer",children:"Chapter 3: Sim2Real Transfer"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Identify and analyze the reality gap between simulation and real-world environments"}),"\n",(0,a.jsx)(n.li,{children:"Apply domain randomization techniques to improve transferability"}),"\n",(0,a.jsx)(n.li,{children:"Implement system identification methods to bridge simulation-reality differences"}),"\n",(0,a.jsx)(n.li,{children:"Design robust control strategies that work in both simulation and reality"}),"\n",(0,a.jsx)(n.li,{children:"Evaluate transfer performance and identify key factors affecting success"}),"\n",(0,a.jsx)(n.li,{children:"Apply Sim2Real transfer techniques to humanoid robot applications"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"physical-ai-concept",children:"Physical AI Concept"}),"\n",(0,a.jsx)(n.p,{children:"Sim2Real (Simulation-to-Reality) transfer is the critical challenge of ensuring behaviors, policies, and controllers learned in simulation environments effectively transfer to real-world robotic systems. This concept is particularly important in Physical AI and humanoid robotics, where the cost, safety, and time constraints of real-world training make simulation-based learning essential, but the differences between simulated and real environments can prevent successful transfer."}),"\n",(0,a.jsx)(n.p,{children:"The Sim2Real problem encompasses:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dynamics Mismatch"}),": Differences in physical properties between simulation and reality"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Perception Gap"}),": Variations in sensor data quality and characteristics"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Actuation Differences"}),": Discrepancies in motor control and response"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Environmental Factors"}),": Unmodeled elements like lighting, texture, and disturbances"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Model Fidelity"}),": Trade-offs between simulation accuracy and computational efficiency"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,a.jsx)(n.h3,{id:"sim2real-transfer-architecture",children:"Sim2Real Transfer Architecture"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Sim2Real Transfer Framework:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Simulation Environment                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   High-Fidelity \u2502  \u2502   Domain        \u2502  \u2502   Curriculum    \u2502    \u2502\n\u2502  \u2502   Simulator     \u2502  \u2502   Randomization \u2502  \u2502   Training      \u2502    \u2502\n\u2502  \u2502  \u2022 Accurate     \u2502  \u2502  \u2022 Visual       \u2502  \u2502  \u2022 Progressive  \u2502    \u2502\n\u2502  \u2502    Physics     \u2502  \u2502  \u2022 Dynamics     \u2502  \u2502    Difficulty   \u2502    \u2502\n\u2502  \u2502  \u2022 Sensor      \u2502  \u2502  \u2022 Materials    \u2502  \u2502  \u2022 Transfer     \u2502    \u2502\n\u2502  \u2502    Modeling    \u2502  \u2502  \u2022 Lighting     \u2502  \u2502    Validation   \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502              \u2502                    \u2502                    \u2502           \u2502\n\u2502              \u25bc                    \u25bc                    \u25bc           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              Reality Gap Analysis                           \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502  \u2502\n\u2502  \u2502  \u2502  Dynamics   \u2502  \u2502  Perception \u2502  \u2502  Control    \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  Modeling   \u2502  \u2502  Alignment  \u2502  \u2502  Robustness \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Friction  \u2502  \u2502  \u2022 Noise    \u2502  \u2502  \u2022 Adaptive \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Inertia   \u2502  \u2502  \u2022 Blur     \u2502  \u2502  \u2022 Recovery \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Compliance\u2502  \u2502  \u2022 Distortion\u2502 \u2502  \u2022 Learning \u2502        \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                     \u2502                            \u2502\n\u2502                                     \u25bc                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              Transfer Validation                            \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502  \u2502\n\u2502  \u2502  \u2502  Performance\u2502  \u2502  Adaptation \u2502  \u2502  Iterative   \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  Comparison \u2502  \u2502  Mechanisms \u2502  \u2502  Refinement  \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Metrics  \u2502  \u2502  \u2022 Online   \u2502  \u2502  \u2022 Model    \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Success  \u2502  \u2502  Adaptation \u2502  \u2502  Improvement \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  Rate       \u2502  \u2502  \u2022 Fine-    \u2502  \u2502  \u2022 Validation \u2502        \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  Tuning     \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                   Real Robot                                \u2502\n        \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n        \u2502  \u2502   Physical      \u2502  \u2502   Real Sensors  \u2502  \u2502  Control    \u2502 \u2502\n        \u2502  \u2502   Hardware      \u2502  \u2502   & Actuators   \u2502  \u2502  Systems    \u2502 \u2502\n        \u2502  \u2502  \u2022 Humanoid     \u2502  \u2502  \u2022 Cameras     \u2502  \u2502  \u2022 Balance  \u2502 \u2502\n        \u2502  \u2502    Robot        \u2502  \u2502  \u2022 LIDAR       \u2502  \u2502  \u2022 Locomotion\u2502\u2502\n        \u2502  \u2502  \u2022 Motors       \u2502  \u2502  \u2022 IMU         \u2502  \u2502  \u2022 Manipulation\u2502\u2502\n        \u2502  \u2502  \u2022 Gears        \u2502  \u2502  \u2022 Force/Torque\u2502  \u2502  \u2022 Planning \u2502 \u2502\n        \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h3,{id:"domain-randomization-pipeline",children:"Domain Randomization Pipeline"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Domain Randomization Process:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Base Model   \u2502\u2500\u2500\u2500\u25b6\u2502  Randomization  \u2502\u2500\u2500\u2500\u25b6\u2502   Policy        \u2502\n\u2502   \u2022 Fixed       \u2502    \u2502  \u2022 Visual       \u2502    \u2502   Training      \u2502\n\u2502   Parameters   \u2502    \u2502  \u2022 Physical     \u2502    \u2502  \u2022 Robust       \u2502\n\u2502                \u2502    \u2502  \u2022 Environmental\u2502    \u2502    Policy       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Reality Gap   \u2502\u2500\u2500\u2500\u25b6\u2502  Generalization \u2502\u2500\u2500\u2500\u25b6\u2502   Real-World   \u2502\n\u2502   Analysis      \u2502    \u2502  Assessment     \u2502    \u2502   Deployment   \u2502\n\u2502  \u2022 Identify     \u2502    \u2502  \u2022 Performance \u2502    \u2502  \u2022 Successful  \u2502\n\u2502    Mismatches   \u2502    \u2502    Across       \u2502    \u2502    Transfer    \u2502\n\u2502  \u2022 Quantify     \u2502    \u2502    Domains     \u2502    \u2502  \u2022 Performance \u2502\n\u2502    Differences  \u2502    \u2502  \u2022 Robustness  \u2502    \u2502    Metrics     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h2,{id:"tools--software",children:"Tools & Software"}),"\n",(0,a.jsx)(n.p,{children:"This chapter uses:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Gazebo"})," - Physics-based simulation for dynamics modeling"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Unity"})," - Visual simulation for perception alignment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"ROS 2"})," - Integration between simulation and reality"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"PyBullet"})," - Physics engine for rapid prototyping"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"OpenAI Gym"})," - Reinforcement learning environment interface"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"MuJoCo"})," - High-fidelity physics simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"System Identification Tools"})," - For modeling reality gaps"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Domain Randomization Libraries"})," - For transfer improvement"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"code--configuration-examples",children:"Code / Configuration Examples"}),"\n",(0,a.jsx)(n.h3,{id:"system-identification-for-dynamics-modeling",children:"System Identification for Dynamics Modeling"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float64MultiArray\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Twist\nimport scipy.optimize as opt\nfrom scipy import signal\n\nclass SystemIdentification(Node):\n    def __init__(self):\n        super().__init__('system_identification')\n\n        # Publishers and subscribers\n        self.cmd_pub = self.create_publisher(Float64MultiArray, '/joint_commands', 10)\n        self.joint_sub = self.create_subscription(JointState, '/joint_states', self.joint_callback, 10)\n\n        # Data collection\n        self.joint_positions = []\n        self.joint_velocities = []\n        self.joint_commands = []\n        self.timestamps = []\n\n        # Timer for data collection\n        self.data_timer = self.create_timer(0.01, self.collect_data)  # 100 Hz\n        self.experiment_timer = self.create_timer(10.0, self.run_identification_experiment)\n\n        # Robot dynamics parameters to identify\n        self.dynamics_params = {\n            'mass': 10.0,  # Base estimate\n            'friction_coeff': 0.1,\n            'inertia': 0.5\n        }\n\n        self.get_logger().info('System identification node initialized')\n\n    def joint_callback(self, msg):\n        \"\"\"Collect joint state data for system identification\"\"\"\n        current_time = self.get_clock().now().nanoseconds / 1e9\n\n        self.joint_positions.append(list(msg.position))\n        self.joint_velocities.append(list(msg.velocity))\n        self.timestamps.append(current_time)\n\n    def collect_data(self):\n        \"\"\"Collect input-output data for system identification\"\"\"\n        # Apply random excitation commands to explore dynamics\n        if len(self.joint_positions) > 0:\n            # Generate random joint commands for excitation\n            random_commands = np.random.uniform(-0.5, 0.5, len(self.joint_positions[-1]))\n            cmd_msg = Float64MultiArray()\n            cmd_msg.data = random_commands.tolist()\n            self.cmd_pub.publish(cmd_msg)\n\n            self.joint_commands.append(random_commands.tolist())\n\n    def run_identification_experiment(self):\n        \"\"\"Run system identification experiment\"\"\"\n        if len(self.joint_positions) > 1000:  # Need sufficient data\n            self.get_logger().info('Starting system identification...')\n\n            # Prepare data for identification\n            positions = np.array(self.joint_positions)\n            velocities = np.array(self.joint_velocities)\n            commands = np.array(self.joint_commands)\n\n            # Estimate dynamics parameters using optimization\n            result = opt.minimize(\n                self.dynamics_cost_function,\n                x0=list(self.dynamics_params.values()),\n                args=(positions, velocities, commands),\n                method='L-BFGS-B'\n            )\n\n            # Update identified parameters\n            param_names = list(self.dynamics_params.keys())\n            for i, name in enumerate(param_names):\n                self.dynamics_params[name] = result.x[i]\n\n            self.get_logger().info(f'Identified dynamics parameters: {self.dynamics_params}')\n\n            # Reset data collection for next iteration\n            self.joint_positions = []\n            self.joint_velocities = []\n            self.joint_commands = []\n            self.timestamps = []\n\n    def dynamics_cost_function(self, params, positions, velocities, commands):\n        \"\"\"Cost function for dynamics parameter estimation\"\"\"\n        mass, friction_coeff, inertia = params\n\n        # Simulate system with current parameters\n        simulated_velocities = []\n        for i in range(1, len(positions)):\n            # Simple dynamics model: mass * acceleration + friction * velocity = command\n            dt = self.timestamps[i] - self.timestamps[i-1] if i > 0 else 0.01\n\n            # Estimate acceleration from velocity\n            if i > 1:\n                acceleration = (velocities[i] - velocities[i-1]) / dt\n            else:\n                acceleration = np.zeros_like(velocities[i])\n\n            # Calculate predicted velocity based on dynamics\n            friction_force = friction_coeff * velocities[i-1]\n            net_force = commands[i-1] - friction_force\n            predicted_acceleration = net_force / mass\n            predicted_velocity = velocities[i-1] + predicted_acceleration * dt\n\n            simulated_velocities.append(predicted_velocity)\n\n        if len(simulated_velocities) > 0:\n            simulated_velocities = np.array(simulated_velocities)\n            actual_velocities = velocities[1:]  # Skip first since we start from index 1\n\n            # Calculate error between actual and simulated\n            error = np.mean((actual_velocities - simulated_velocities)**2)\n            return error\n        else:\n            return float('inf')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SystemIdentification()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"domain-randomization-environment",children:"Domain Randomization Environment"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import random\nimport numpy as np\nimport gym\nfrom gym import spaces\nimport pybullet as p\nimport pybullet_data\n\nclass DomainRandomizationEnv(gym.Env):\n    """Gym environment with domain randomization for Sim2Real transfer"""\n\n    def __init__(self):\n        super(DomainRandomizationEnv, self).__init__()\n\n        # Define action and observation spaces\n        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(4,), dtype=np.float32)\n        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(12,), dtype=np.float32)\n\n        # Physics parameters to randomize\n        self.param_ranges = {\n            \'gravity\': [-10.5, -9.5],  # Gravity range\n            \'friction\': [0.1, 0.9],    # Friction coefficient\n            \'restitution\': [0.0, 0.5], # Bounce coefficient\n            \'mass_multiplier\': [0.8, 1.2], # Mass scaling\n        }\n\n        # Visual parameters to randomize\n        self.visual_ranges = {\n            \'light_intensity\': [0.5, 2.0],\n            \'floor_color_var\': [0.1, 0.9],\n        }\n\n        # Connect to PyBullet\n        self.physics_client = p.connect(p.DIRECT)  # Use DIRECT for training, SHARED_MEMORY for GUI\n        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n\n        # Initialize environment\n        self.reset()\n\n    def reset(self):\n        """Reset environment with randomized parameters"""\n        # Randomize physics parameters\n        self.randomize_physics()\n\n        # Randomize visual parameters\n        self.randomize_visual()\n\n        # Reset robot position and state\n        self.reset_robot()\n\n        # Return initial observation\n        return self.get_observation()\n\n    def randomize_physics(self):\n        """Randomize physics parameters"""\n        # Set random gravity\n        gravity_range = self.param_ranges[\'gravity\']\n        gravity_z = random.uniform(gravity_range[0], gravity_range[1])\n        p.setGravity(0, 0, gravity_z, physicsClientId=self.physics_client)\n\n        # Randomize other physics parameters as needed\n        # This is a simplified example - real implementation would be more complex\n        pass\n\n    def randomize_visual(self):\n        """Randomize visual parameters"""\n        # In a real implementation, this would randomize lighting, textures, etc.\n        # For PyBullet, we can randomize floor color\n        floor_color_range = self.visual_ranges[\'floor_color_var\']\n        color_val = random.uniform(floor_color_range[0], floor_color_range[1])\n        p.changeVisualShape(-1, -1, rgbaColor=[color_val, color_val, color_val, 1])\n\n    def reset_robot(self):\n        """Reset robot to initial state"""\n        # Load plane\n        self.plane_id = p.loadURDF("plane.urdf")\n\n        # Load a simple robot (replace with your robot URDF)\n        self.robot_id = p.loadURDF("r2d2.urdf", [0, 0, 1])\n\n        # Reset joint positions\n        num_joints = p.getNumJoints(self.robot_id)\n        for i in range(num_joints):\n            p.resetJointState(self.robot_id, i, targetValue=0)\n\n    def step(self, action):\n        """Execute action in environment"""\n        # Apply action to robot\n        self.apply_action(action)\n\n        # Step simulation\n        p.stepSimulation(physicsClientId=self.physics_client)\n\n        # Get observation\n        obs = self.get_observation()\n\n        # Calculate reward (simplified)\n        reward = self.calculate_reward()\n\n        # Check if episode is done\n        done = self.is_done()\n\n        # Info dictionary\n        info = {}\n\n        return obs, reward, done, info\n\n    def apply_action(self, action):\n        """Apply action to robot"""\n        # In a real implementation, this would apply torques or positions to joints\n        # This is a simplified example\n        num_joints = p.getNumJoints(self.robot_id)\n        for i in range(min(len(action), num_joints)):\n            p.setJointMotorControl2(\n                bodyIndex=self.robot_id,\n                jointIndex=i,\n                controlMode=p.VELOCITY_CONTROL,\n                targetVelocity=action[i] * 10.0  # Scale action\n            )\n\n    def get_observation(self):\n        """Get current observation"""\n        # Get robot state (position, velocity, etc.)\n        robot_pos, robot_orn = p.getBasePositionAndOrientation(self.robot_id)\n        robot_vel, robot_angular_vel = p.getBaseVelocity(self.robot_id)\n\n        # Get joint states\n        joint_states = []\n        num_joints = p.getNumJoints(self.robot_id)\n        for i in range(num_joints):\n            joint_state = p.getJointState(self.robot_id, i)\n            joint_states.extend([joint_state[0], joint_state[1]])  # position, velocity\n\n        # Combine all observations\n        obs = np.concatenate([\n            robot_pos,\n            robot_orn,  # Using orientation as quaternion\n            robot_vel,\n            robot_angular_vel,\n            joint_states[:4]  # Limit for space\n        ])\n\n        return obs.astype(np.float32)\n\n    def calculate_reward(self):\n        """Calculate reward for current state"""\n        # Simplified reward - in practice this would be more complex\n        robot_pos = p.getBasePositionAndOrientation(self.robot_id)[0]\n        # Reward for moving forward (positive x direction)\n        reward = robot_pos[0] * 0.1\n        return reward\n\n    def is_done(self):\n        """Check if episode is done"""\n        # Simplified termination condition\n        robot_pos = p.getBasePositionAndOrientation(self.robot_id)[0]\n        # End if robot falls too low\n        return robot_pos[2] < 0.1\n\n    def close(self):\n        """Close the environment"""\n        p.disconnect(physicsClientId=self.physics_client)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"robust-control-with-adaptation",children:"Robust Control with Adaptation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float64MultiArray\nfrom sensor_msgs.msg import JointState, Imu\nfrom geometry_msgs.msg import Twist\nimport math\n\nclass RobustAdaptiveController(Node):\n    def __init__(self):\n        super().__init__('robust_adaptive_controller')\n\n        # Publishers and subscribers\n        self.cmd_pub = self.create_publisher(Float64MultiArray, '/joint_commands', 10)\n        self.joint_sub = self.create_subscription(JointState, '/joint_states', self.joint_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, '/imu/data', self.imu_callback, 10)\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.01, self.control_loop)  # 100 Hz\n\n        # Robot state\n        self.current_positions = {}\n        self.current_velocities = {}\n        self.imu_data = None\n\n        # Adaptive control parameters\n        self.adaptation_rate = 0.01\n        self.estimated_params = {\n            'mass': 10.0,\n            'friction': 0.1,\n            'gravity_compensation': 9.81\n        }\n\n        # Reference trajectory\n        self.trajectory_time = 0.0\n        self.trajectory_amplitude = 0.5\n        self.trajectory_frequency = 0.5\n\n        # Control gains\n        self.kp = 100.0  # Proportional gain\n        self.kd = 10.0   # Derivative gain\n\n        self.get_logger().info('Robust adaptive controller initialized')\n\n    def joint_callback(self, msg):\n        \"\"\"Process joint state data\"\"\"\n        for i, name in enumerate(msg.name):\n            if i < len(msg.position):\n                self.current_positions[name] = msg.position[i]\n            if i < len(msg.velocity):\n                self.current_velocities[name] = msg.velocity[i]\n\n    def imu_callback(self, msg):\n        \"\"\"Process IMU data for balance control\"\"\"\n        self.imu_data = msg\n\n    def control_loop(self):\n        \"\"\"Main adaptive control loop\"\"\"\n        if not self.current_positions or not self.imu_data:\n            return\n\n        # Update trajectory time\n        self.trajectory_time += 0.01  # 100 Hz\n\n        # Get first joint for demonstration (in practice, you'd control all joints)\n        joint_names = list(self.current_positions.keys())\n        if not joint_names:\n            return\n\n        joint_name = joint_names[0]\n        current_pos = self.current_positions[joint_name]\n        current_vel = self.current_velocities.get(joint_name, 0.0)\n\n        # Generate reference trajectory\n        reference_pos = self.trajectory_amplitude * math.sin(\n            2 * math.pi * self.trajectory_frequency * self.trajectory_time\n        )\n        reference_vel = self.trajectory_amplitude * 2 * math.pi * self.trajectory_frequency * math.cos(\n            2 * math.pi * self.trajectory_frequency * self.trajectory_time\n        )\n\n        # Calculate tracking error\n        pos_error = reference_pos - current_pos\n        vel_error = reference_vel - current_vel\n\n        # Adaptive parameter estimation (simplified)\n        self.update_parameter_estimates(pos_error, vel_error, current_vel)\n\n        # Calculate control command with adaptive parameters\n        control_effort = (\n            self.kp * pos_error +\n            self.kd * vel_error +\n            self.estimated_params['friction'] * current_vel +\n            self.estimated_params['gravity_compensation'] * math.sin(current_pos)\n        )\n\n        # Apply control limits\n        control_effort = max(-100.0, min(100.0, control_effort))\n\n        # Publish command\n        cmd_msg = Float64MultiArray()\n        cmd_msg.data = [float(control_effort)]  # For the first joint\n        self.cmd_pub.publish(cmd_msg)\n\n        # Log control information\n        self.get_logger().debug(\n            f'Joint: {joint_name}, Pos: {current_pos:.3f}, Ref: {reference_pos:.3f}, '\n            f'Error: {pos_error:.3f}, Control: {control_effort:.3f}, '\n            f'Params: {self.estimated_params}'\n        )\n\n    def update_parameter_estimates(self, pos_error, vel_error, velocity):\n        \"\"\"Update estimated parameters using adaptive law\"\"\"\n        # Simplified parameter adaptation\n        # In practice, this would use more sophisticated algorithms\n\n        # Adapt friction estimate based on velocity and error\n        friction_correction = self.adaptation_rate * velocity * pos_error\n        self.estimated_params['friction'] = max(0.01,\n            self.estimated_params['friction'] + friction_correction)\n\n        # Adapt mass estimate based on acceleration error\n        # This is a simplified example - real adaptation would be more complex\n        acceleration_error = pos_error * 10.0  # Rough estimate\n        mass_correction = self.adaptation_rate * abs(acceleration_error) * 0.1\n        self.estimated_params['mass'] = max(1.0,\n            self.estimated_params['mass'] + mass_correction)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = RobustAdaptiveController()\n\n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"practical-lab--simulation",children:"Practical Lab / Simulation"}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-1-reality-gap-analysis",children:"Lab Exercise 1: Reality Gap Analysis"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Set up a simple simulation environment (using Gazebo or PyBullet)"}),"\n",(0,a.jsx)(n.li,{children:"Create a physical model of the same robot"}),"\n",(0,a.jsx)(n.li,{children:"Execute identical commands in both environments"}),"\n",(0,a.jsx)(n.li,{children:"Compare the resulting trajectories and identify differences"}),"\n",(0,a.jsx)(n.li,{children:"Document the key factors causing the reality gap"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-2-domain-randomization-implementation",children:"Lab Exercise 2: Domain Randomization Implementation"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement domain randomization in your simulation environment"}),"\n",(0,a.jsxs)(n.li,{children:["Randomize key parameters like:","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Visual properties (lighting, textures, colors)"}),"\n",(0,a.jsx)(n.li,{children:"Physical properties (friction, mass, damping)"}),"\n",(0,a.jsx)(n.li,{children:"Environmental properties (gravity, wind)"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:"Train a simple controller with domain randomization"}),"\n",(0,a.jsx)(n.li,{children:"Test the controller's robustness to parameter variations"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-3-system-identification",children:"Lab Exercise 3: System Identification"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Collect input-output data from your real robot or high-fidelity simulation"}),"\n",(0,a.jsx)(n.li,{children:"Implement system identification techniques to estimate dynamics parameters"}),"\n",(0,a.jsx)(n.li,{children:"Compare identified parameters with nominal values"}),"\n",(0,a.jsx)(n.li,{children:"Use identified parameters to improve simulation fidelity"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-4-adaptive-control-design",children:"Lab Exercise 4: Adaptive Control Design"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement an adaptive controller that adjusts to changing dynamics"}),"\n",(0,a.jsx)(n.li,{children:"Test the controller in simulation with varying parameters"}),"\n",(0,a.jsx)(n.li,{children:"Evaluate the controller's ability to maintain performance despite model uncertainty"}),"\n",(0,a.jsx)(n.li,{children:"Analyze the adaptation rate and stability properties"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-5-transfer-validation",children:"Lab Exercise 5: Transfer Validation"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Train a policy in simulation with domain randomization"}),"\n",(0,a.jsx)(n.li,{children:"Deploy the policy to a real robot or more accurate simulation"}),"\n",(0,a.jsx)(n.li,{children:"Measure performance degradation and identify key transfer barriers"}),"\n",(0,a.jsx)(n.li,{children:"Iterate on the simulation model to improve transfer performance"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-6-curriculum-learning-for-transfer",children:"Lab Exercise 6: Curriculum Learning for Transfer"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Design a curriculum of increasingly complex tasks"}),"\n",(0,a.jsx)(n.li,{children:"Start with simplified simulation and gradually increase realism"}),"\n",(0,a.jsx)(n.li,{children:"Train policies at each level of the curriculum"}),"\n",(0,a.jsx)(n.li,{children:"Evaluate the effectiveness of curriculum learning for Sim2Real transfer"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"real-world-mapping",children:"Real-World Mapping"}),"\n",(0,a.jsx)(n.h3,{id:"industrial-applications",children:"Industrial Applications"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Manufacturing"}),": Robots trained in simulation with domain randomization for real-world assembly tasks"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Logistics"}),": Warehouse robots with Sim2Real transfer for navigation and manipulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Agriculture"}),": Autonomous vehicles with simulation-trained perception systems"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"research-applications",children:"Research Applications"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Boston Dynamics"}),": Extensive use of simulation with domain randomization for quadruped locomotion"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"DeepMind"}),": Sim2Real transfer for dexterous manipulation tasks"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"OpenAI"}),": Domain randomization for robotic hand manipulation"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"key-success-factors",children:"Key Success Factors"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Parameter Coverage"}),": Ensuring randomization covers the range of real-world parameters"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Validation"}),": Systematic testing of transfer performance"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Iterative Refinement"}),": Continuous improvement of simulation models"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Robust Control"}),": Controllers that can handle model uncertainty"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sensory Alignment"}),": Matching simulated and real sensor characteristics"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"Chapter 3 has covered the critical challenge of Sim2Real transfer in Physical AI and humanoid robotics. We've explored the reality gap problem, domain randomization techniques, system identification methods, and adaptive control strategies. The examples demonstrated practical implementations of system identification, domain randomization environments, and robust adaptive controllers. The hands-on lab exercises provide experience with analyzing reality gaps, implementing transfer techniques, and validating performance. This knowledge is essential for developing humanoid robots that can effectively transfer skills learned in simulation to real-world applications."})]})}function m(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var t=i(6540);const a={},o=t.createContext(a);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);