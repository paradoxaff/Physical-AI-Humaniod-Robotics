"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[13],{8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>l});var s=t(6540);const a={},r=s.createContext(a);function i(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(r.Provider,{value:n},e.children)}},8463:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"modules/module-01-ros2/python-agents-rclpy","title":"Lesson 3 - Python Agents with rclpy","description":"Learning Objectives","source":"@site/docs/modules/module-01-ros2/python-agents-rclpy.mdx","sourceDirName":"modules/module-01-ros2","slug":"/modules/module-01-ros2/python-agents-rclpy","permalink":"/docs/modules/module-01-ros2/python-agents-rclpy","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/modules/module-01-ros2/python-agents-rclpy.mdx","tags":[],"version":"current","frontMatter":{"title":"Lesson 3 - Python Agents with rclpy","sidebar_label":"Python Agents with rclpy"},"sidebar":"tutorialSidebar","previous":{"title":"Physical AI and the Robotic Nervous System","permalink":"/docs/modules/module-01-ros2/physical-ai-robotic-nervous-system"},"next":{"title":"ROS 2 Foundations","permalink":"/docs/modules/module-01-ros2/ros2-foundations"}}');var a=t(4848),r=t(8453);const i={title:"Lesson 3 - Python Agents with rclpy",sidebar_label:"Python Agents with rclpy"},l="Lesson 3: Python Agents with rclpy",o={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Physical AI Concept",id:"physical-ai-concept",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Agent Architecture Pattern",id:"agent-architecture-pattern",level:3},{value:"Multi-Agent Coordination",id:"multi-agent-coordination",level:3},{value:"Tools &amp; Software",id:"tools--software",level:2},{value:"Code / Configuration Examples",id:"code--configuration-examples",level:2},{value:"Basic Agent with State Management",id:"basic-agent-with-state-management",level:3},{value:"Multi-Threaded Agent with Asynchronous Services",id:"multi-threaded-agent-with-asynchronous-services",level:3},{value:"Agent with Parameters and Configuration",id:"agent-with-parameters-and-configuration",level:3},{value:"Practical Lab / Simulation",id:"practical-lab--simulation",level:2},{value:"Lab Exercise 1: Basic Agent Implementation",id:"lab-exercise-1-basic-agent-implementation",level:3},{value:"Lab Exercise 2: Multi-Threaded Agent",id:"lab-exercise-2-multi-threaded-agent",level:3},{value:"Lab Exercise 3: Configurable Agent",id:"lab-exercise-3-configurable-agent",level:3},{value:"Lab Exercise 4: Agent Coordination",id:"lab-exercise-4-agent-coordination",level:3},{value:"Real-World Mapping",id:"real-world-mapping",level:2},{value:"Industrial Applications",id:"industrial-applications",level:3},{value:"Service Robotics",id:"service-robotics",level:3},{value:"Research Platforms",id:"research-platforms",level:3},{value:"Key Design Patterns",id:"key-design-patterns",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"lesson-3-python-agents-with-rclpy",children:"Lesson 3: Python Agents with rclpy"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Create sophisticated Python agents using rclpy"}),"\n",(0,a.jsx)(n.li,{children:"Implement agent behaviors with state management"}),"\n",(0,a.jsx)(n.li,{children:"Design multi-threaded ROS 2 nodes for complex applications"}),"\n",(0,a.jsx)(n.li,{children:"Use ROS 2 parameters for agent configuration"}),"\n",(0,a.jsx)(n.li,{children:"Implement lifecycle management for robust agents"}),"\n",(0,a.jsx)(n.li,{children:"Apply design patterns for agent-based robotics"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"physical-ai-concept",children:"Physical AI Concept"}),"\n",(0,a.jsx)(n.p,{children:"Python agents in ROS 2 represent autonomous entities that can perceive their environment, make decisions, and execute actions. These agents embody the principles of Physical AI by bridging the gap between high-level AI algorithms and low-level physical control. Through rclpy, agents can integrate perception, planning, and control in a cohesive manner, enabling complex behaviors that emerge from the interaction of multiple specialized components."}),"\n",(0,a.jsx)(n.p,{children:"Agent-based approaches in Physical AI provide:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Autonomy"}),": Agents can operate independently with minimal human intervention"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Adaptability"}),": Agents can modify their behavior based on environmental conditions"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Scalability"}),": Multiple agents can coordinate to solve complex problems"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Robustness"}),": Failure of one agent doesn't necessarily compromise the entire system"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Intelligence"}),": Agents can incorporate learning, reasoning, and planning capabilities"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,a.jsx)(n.h3,{id:"agent-architecture-pattern",children:"Agent Architecture Pattern"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Agent Node                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502   Perception    \u2502  \u2502   Decision      \u2502  \u2502   Action        \u2502    \u2502\n\u2502  \u2502   Component     \u2502  \u2502   Component     \u2502  \u2502   Component     \u2502    \u2502\n\u2502  \u2502  \u2022 Sensor       \u2502  \u2502  \u2022 State        \u2502  \u2502  \u2022 Motor        \u2502    \u2502\n\u2502  \u2502    Processing   \u2502  \u2502    Machine      \u2502  \u2502    Commands     \u2502    \u2502\n\u2502  \u2502  \u2022 Feature      \u2502  \u2502  \u2022 Planning     \u2502  \u2502  \u2022 Trajectory   \u2502    \u2502\n\u2502  \u2502    Extraction   \u2502  \u2502  \u2022 Learning     \u2502  \u2502    Execution    \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502              \u2502                    \u2502                    \u2502           \u2502\n\u2502              \u25bc                    \u25bc                    \u25bc           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                    Agent State                              \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502  \u2502\n\u2502  \u2502  \u2502   Goals     \u2502  \u2502  Internal   \u2502  \u2502  Behavior   \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502             \u2502  \u2502   World     \u2502  \u2502   Modes     \u2502        \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                     \u2502                            \u2502\n\u2502                                     \u25bc                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                  Communication Layer                        \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502  \u2502\n\u2502  \u2502  \u2502   Topics    \u2502  \u2502   Services  \u2502  \u2502  Actions    \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Publish  \u2502  \u2502  \u2022 Request  \u2502  \u2502  \u2022 Goals    \u2502        \u2502  \u2502\n\u2502  \u2502  \u2502  \u2022 Subscribe\u2502  \u2502  \u2022 Response \u2502  \u2502  \u2022 Feedback  \u2502        \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h3,{id:"multi-agent-coordination",children:"Multi-Agent Coordination"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Agent Coordination Pattern:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Navigation    \u2502    \u2502   Manipulation  \u2502    \u2502   Perception    \u2502\n\u2502   Agent         \u2502    \u2502   Agent         \u2502    \u2502   Agent         \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502 \u2022 Path planning \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Grasping      \u2502\u25c4\u2500\u2500\u25ba\u2502 \u2022 Object        \u2502\n\u2502 \u2022 Obstacle      \u2502    \u2502 \u2022 Manipulation  \u2502    \u2502   Detection     \u2502\n\u2502   avoidance     \u2502    \u2502 \u2022 Tool use      \u2502    \u2502 \u2022 Scene         \u2502\n\u2502 \u2022 Localization  \u2502    \u2502 \u2022 Force control \u2502    \u2502   Understanding \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502                       \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   Coordination  \u2502\n                    \u2502   Agent         \u2502\n                    \u2502  (Optional)     \u2502\n                    \u2502 \u2022 Task          \u2502\n                    \u2502   Scheduling    \u2502\n                    \u2502 \u2022 Resource      \u2502\n                    \u2502   Management    \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h2,{id:"tools--software",children:"Tools & Software"}),"\n",(0,a.jsx)(n.p,{children:"This lesson uses:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"ROS 2 Humble Hawksbill"})," - Core framework"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"rclpy"})," - Python client library for agent implementation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Python 3.8+"})," - For agent logic and algorithms"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"NumPy/SciPy"})," - For mathematical computations"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"OpenCV"})," - For computer vision components"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Transforms3d"})," - For 3D transformations"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"PyGame"})," - For simulation and visualization (optional)"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"code--configuration-examples",children:"Code / Configuration Examples"}),"\n",(0,a.jsx)(n.h3,{id:"basic-agent-with-state-management",children:"Basic Agent with State Management"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nfrom nav_msgs.msg import Odometry\nimport numpy as np\nimport math\nfrom enum import Enum\n\nclass AgentState(Enum):\n    IDLE = 1\n    EXPLORING = 2\n    NAVIGATING = 3\n    AVOIDING_OBSTACLE = 4\n    RECHARGING = 5\n\nclass ExplorationAgent(Node):\n    def __init__(self):\n        super().__init__(\'exploration_agent\')\n\n        # Agent state management\n        self.state = AgentState.IDLE\n        self.target_pose = None\n        self.current_pose = None\n        self.battery_level = 100.0\n\n        # QoS profile for sensor data\n        qos_profile = QoSProfile(\n            depth=10,\n            reliability=ReliabilityPolicy.BEST_EFFORT\n        )\n\n        # Publishers and subscribers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.status_pub = self.create_publisher(String, \'/agent/status\', 10)\n\n        self.scan_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.scan_callback, qos_profile\n        )\n        self.odom_sub = self.create_subscription(\n            Odometry, \'/odom\', self.odom_callback, qos_profile\n        )\n\n        # Timer for agent behavior loop\n        self.behavior_timer = self.create_timer(0.1, self.behavior_callback)\n\n        # Parameters for agent configuration\n        self.declare_parameter(\'safety_distance\', 0.5)\n        self.declare_parameter(\'exploration_speed\', 0.3)\n        self.declare_parameter(\'rotation_speed\', 0.5)\n\n        self.get_logger().info(\'Exploration agent initialized\')\n\n    def scan_callback(self, msg):\n        """Process laser scan data for obstacle detection"""\n        # Find minimum distance in front of robot\n        front_scan = msg.ranges[len(msg.ranges)//2 - 30 : len(msg.ranges)//2 + 30]\n        valid_ranges = [r for r in front_scan if not (math.isnan(r) or math.isinf(r))]\n\n        if valid_ranges:\n            min_distance = min(valid_ranges)\n            self.check_obstacle_proximity(min_distance)\n\n    def odom_callback(self, msg):\n        """Update current pose from odometry"""\n        self.current_pose = msg.pose.pose\n\n        # Simulate battery drain based on movement\n        if self.current_pose:\n            # In a real system, this would be based on actual power consumption\n            self.battery_level = max(0.0, self.battery_level - 0.001)\n\n    def check_obstacle_proximity(self, min_distance):\n        """Check if agent needs to avoid obstacles"""\n        safety_distance = self.get_parameter(\'safety_distance\').value\n\n        if min_distance < safety_distance and self.state != AgentState.AVOIDING_OBSTACLE:\n            self.state = AgentState.AVOIDING_OBSTACLE\n            self.get_logger().info(f\'Obstacle detected at {min_distance:.2f}m, switching to avoidance mode\')\n\n    def behavior_callback(self):\n        """Main agent behavior loop"""\n        # Update agent status\n        status_msg = String()\n        status_msg.data = f\'State: {self.state.name}, Battery: {self.battery_level:.1f}%\'\n        self.status_pub.publish(status_msg)\n\n        # Execute behavior based on current state\n        if self.state == AgentState.IDLE:\n            self.handle_idle_state()\n        elif self.state == AgentState.EXPLORING:\n            self.handle_exploring_state()\n        elif self.state == AgentState.NAVIGATING:\n            self.handle_navigating_state()\n        elif self.state == AgentState.AVOIDING_OBSTACLE:\n            self.handle_avoiding_obstacle_state()\n        elif self.state == AgentState.RECHARGING:\n            self.handle_recharging_state()\n\n    def handle_idle_state(self):\n        """Handle idle state - look for exploration opportunities"""\n        # If battery is sufficient, start exploring\n        if self.battery_level > 20.0:\n            self.state = AgentState.EXPLORING\n            self.get_logger().info(\'Starting exploration\')\n        else:\n            self.get_logger().info(\'Battery low, need to recharge\')\n\n    def handle_exploring_state(self):\n        """Handle exploration state - move forward with obstacle avoidance"""\n        msg = Twist()\n\n        # Check if we need to avoid obstacles\n        if self.state == AgentState.AVOIDING_OBSTACLE:\n            return  # Let avoidance behavior take over\n\n        # Move forward at exploration speed\n        exploration_speed = self.get_parameter(\'exploration_speed\').value\n        msg.linear.x = exploration_speed\n\n        # Publish movement command\n        self.cmd_vel_pub.publish(msg)\n\n    def handle_avoiding_obstacle_state(self):\n        """Handle obstacle avoidance behavior"""\n        msg = Twist()\n\n        # Rotate to avoid obstacle\n        rotation_speed = self.get_parameter(\'rotation_speed\').value\n        msg.angular.z = rotation_speed\n\n        # Publish rotation command\n        self.cmd_vel_pub.publish(msg)\n\n        # Check if obstacle is cleared\n        # In a real implementation, this would check if the path is clear\n        # For simulation, we\'ll return to exploration after a short time\n        self.avoidance_timer = self.create_timer(2.0, self.clear_obstacle_avoidance)\n\n    def clear_obstacle_avoidance(self):\n        """Callback to clear obstacle avoidance state"""\n        self.state = AgentState.EXPLORING\n        self.destroy_timer(self.avoidance_timer)\n        self.get_logger().info(\'Obstacle avoided, resuming exploration\')\n\n    def handle_recharging_state(self):\n        """Handle recharging state"""\n        # Stop movement\n        msg = Twist()\n        self.cmd_vel_pub.publish(msg)\n        self.get_logger().info(\'Recharging...\')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = ExplorationAgent()\n\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"multi-threaded-agent-with-asynchronous-services",children:"Multi-Threaded Agent with Asynchronous Services"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile\nfrom rclpy.executors import MultiThreadedExecutor\nfrom rclpy.callback_groups import MutuallyExclusiveCallbackGroup\nfrom std_msgs.msg import String\nfrom example_interfaces.srv import Trigger\nimport threading\nimport time\nimport queue\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass MultiThreadedAgent(Node):\n    def __init__(self):\n        super().__init__(\'multithreaded_agent\')\n\n        # Create callback groups for thread safety\n        self.sensor_cb_group = MutuallyExclusiveCallbackGroup()\n        self.service_cb_group = MutuallyExclusiveCallbackGroup()\n        self.timer_cb_group = MutuallyExclusiveCallbackGroup()\n\n        # Publishers\n        self.status_pub = self.create_publisher(String, \'/agent/multi_status\', 10)\n\n        # Service server\n        self.task_service = self.create_service(\n            Trigger,\n            \'/agent/execute_task\',\n            self.execute_task_callback,\n            callback_group=self.service_cb_group\n        )\n\n        # Timer for background tasks\n        self.background_timer = self.create_timer(\n            1.0, self.background_task, callback_group=self.timer_cb_group\n        )\n\n        # Thread pool for background processing\n        self.executor_pool = ThreadPoolExecutor(max_workers=3)\n\n        # Shared data structures\n        self.task_queue = queue.Queue()\n        self.results_queue = queue.Queue()\n\n        # Agent state\n        self.is_processing = False\n\n        self.get_logger().info(\'Multi-threaded agent initialized\')\n\n    def execute_task_callback(self, request, response):\n        """Service callback to execute tasks in background thread"""\n        self.get_logger().info(\'Received task request\')\n\n        # Add task to queue for background processing\n        task_id = f"task_{int(time.time())}"\n        self.task_queue.put(task_id)\n\n        # Start background processing if not already running\n        if not self.is_processing:\n            self.executor_pool.submit(self.process_tasks)\n            self.is_processing = True\n\n        response.success = True\n        response.message = f\'Task {task_id} queued for processing\'\n        return response\n\n    def process_tasks(self):\n        """Background thread to process tasks"""\n        while not self.task_queue.empty():\n            try:\n                task_id = self.task_queue.get_nowait()\n                self.get_logger().info(f\'Processing task: {task_id}\')\n\n                # Simulate task processing\n                time.sleep(2)  # Simulate processing time\n\n                # Process the task (in a real system, this would do actual work)\n                result = self.perform_task(task_id)\n\n                # Put result in results queue\n                self.results_queue.put((task_id, result))\n\n                # Update status\n                status_msg = String()\n                status_msg.data = f\'Task {task_id} completed with result: {result}\'\n                self.status_pub.publish(status_msg)\n\n            except queue.Empty:\n                break\n            except Exception as e:\n                self.get_logger().error(f\'Error processing task: {str(e)}\')\n\n        self.is_processing = False\n\n    def perform_task(self, task_id):\n        """Perform the actual task work"""\n        # Simulate different types of tasks\n        if \'task_\' in task_id:\n            # Simulate some computation\n            import random\n            result = f"processed_{random.randint(1, 100)}"\n            return result\n\n    def background_task(self):\n        """Background task running in main thread"""\n        # Check for completed tasks and process results\n        while not self.results_queue.empty():\n            try:\n                task_id, result = self.results_queue.get_nowait()\n                self.get_logger().info(f\'Background: Task {task_id} result: {result}\')\n            except queue.Empty:\n                break\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    # Create agent\n    agent = MultiThreadedAgent()\n\n    # Create multi-threaded executor\n    executor = MultiThreadedExecutor(num_threads=4)\n    executor.add_node(agent)\n\n    try:\n        executor.spin()\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.executor_pool.shutdown(wait=True)\n        agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"agent-with-parameters-and-configuration",children:"Agent with Parameters and Configuration"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport math\n\nclass ConfigurableAgent(Node):\n    def __init__(self):\n        super().__init__('configurable_agent')\n\n        # Declare parameters with defaults\n        self.declare_parameter('agent_name', 'default_agent')\n        self.declare_parameter('movement_speed', 0.5)\n        self.declare_parameter('rotation_speed', 0.8)\n        self.declare_parameter('safety_distance', 0.6)\n        self.declare_parameter('exploration_pattern', 'spiral')  # spiral, grid, random\n        self.declare_parameter('battery_threshold', 20.0)\n        self.declare_parameter('communication_timeout', 5.0)\n\n        # Get parameter values\n        self.agent_name = self.get_parameter('agent_name').value\n        self.movement_speed = self.get_parameter('movement_speed').value\n        self.rotation_speed = self.get_parameter('rotation_speed').value\n        self.safety_distance = self.get_parameter('safety_distance').value\n        self.exploration_pattern = self.get_parameter('exploration_pattern').value\n        self.battery_threshold = self.get_parameter('battery_threshold').value\n        self.comm_timeout = self.get_parameter('communication_timeout').value\n\n        # Publishers and subscribers\n        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.status_pub = self.create_publisher(String, '/agent/config_status', 10)\n\n        self.scan_sub = self.create_subscription(\n            LaserScan, '/scan', self.scan_callback, QoSProfile(depth=10)\n        )\n\n        # Timer for behavior\n        self.behavior_timer = self.create_timer(0.1, self.behavior_callback)\n\n        # Parameter callback\n        self.add_on_set_parameters_callback(self.parameter_callback)\n\n        # Agent state\n        self.min_scan_distance = float('inf')\n        self.last_communication_time = self.get_clock().now().nanoseconds / 1e9\n\n        self.get_logger().info(f'Configurable agent \"{self.agent_name}\" initialized')\n\n    def parameter_callback(self, params):\n        \"\"\"Callback for parameter changes\"\"\"\n        for param in params:\n            if param.name == 'movement_speed':\n                self.movement_speed = param.value\n                self.get_logger().info(f'Movement speed updated to {self.movement_speed}')\n            elif param.name == 'safety_distance':\n                self.safety_distance = param.value\n                self.get_logger().info(f'Safety distance updated to {self.safety_distance}')\n            elif param.name == 'exploration_pattern':\n                self.exploration_pattern = param.value\n                self.get_logger().info(f'Exploration pattern updated to {self.exploration_pattern}')\n\n        return SetParametersResult(successful=True)\n\n    def scan_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        # Calculate minimum distance in front\n        front_ranges = msg.ranges[len(msg.ranges)//2 - 20 : len(msg.ranges)//2 + 20]\n        valid_ranges = [r for r in front_ranges if not (math.isnan(r) or math.isinf(r))]\n\n        if valid_ranges:\n            self.min_scan_distance = min(valid_ranges)\n        else:\n            self.min_scan_distance = float('inf')\n\n    def behavior_callback(self):\n        \"\"\"Main behavior based on current configuration\"\"\"\n        # Update communication time\n        current_time = self.get_clock().now().nanoseconds / 1e9\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f'Agent: {self.agent_name}, Distance: {self.min_scan_distance:.2f}m, Pattern: {self.exploration_pattern}'\n        self.status_pub.publish(status_msg)\n\n        # Execute behavior based on current configuration\n        if self.min_scan_distance < self.safety_distance:\n            self.execute_avoidance_behavior()\n        else:\n            self.execute_exploration_behavior()\n\n    def execute_avoidance_behavior(self):\n        \"\"\"Execute obstacle avoidance based on current configuration\"\"\"\n        cmd = Twist()\n\n        # Rotate away from obstacle\n        cmd.angular.z = self.rotation_speed\n        cmd.linear.x = 0.0  # Stop forward movement\n\n        self.cmd_vel_pub.publish(cmd)\n        self.get_logger().debug('Executing avoidance behavior')\n\n    def execute_exploration_behavior(self):\n        \"\"\"Execute exploration based on configured pattern\"\"\"\n        cmd = Twist()\n\n        if self.exploration_pattern == 'spiral':\n            # Spiral pattern: forward movement with slow rotation\n            cmd.linear.x = self.movement_speed\n            cmd.angular.z = self.rotation_speed * 0.3\n        elif self.exploration_pattern == 'grid':\n            # Grid pattern: straight line until boundary detected\n            cmd.linear.x = self.movement_speed\n            cmd.angular.z = 0.0\n        elif self.exploration_pattern == 'random':\n            # Random pattern: random movement\n            import random\n            cmd.linear.x = self.movement_speed * random.uniform(0.5, 1.0)\n            cmd.angular.z = self.rotation_speed * random.uniform(-0.5, 0.5)\n        else:\n            # Default to spiral\n            cmd.linear.x = self.movement_speed\n            cmd.angular.z = self.rotation_speed * 0.3\n\n        self.cmd_vel_pub.publish(cmd)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = ConfigurableAgent()\n\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"practical-lab--simulation",children:"Practical Lab / Simulation"}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-1-basic-agent-implementation",children:"Lab Exercise 1: Basic Agent Implementation"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Create a new ROS 2 package for the agent examples:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python agent_tutorial\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Implement the ExplorationAgent from the first example in ",(0,a.jsx)(n.code,{children:"agent_tutorial/exploration_agent.py"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Add the necessary dependencies to ",(0,a.jsx)(n.code,{children:"setup.py"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"install_requires=['setuptools', 'numpy'],\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Build and run the agent:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build --packages-select agent_tutorial\nsource install/setup.bash\nros2 run agent_tutorial exploration_agent\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Monitor the agent's behavior:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# View status messages\nros2 topic echo /agent/status\n\n# View movement commands\nros2 topic echo /cmd_vel\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Experiment with different parameters by setting them at runtime:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"ros2 param set /exploration_agent safety_distance 0.8\nros2 param set /exploration_agent exploration_speed 0.2\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-2-multi-threaded-agent",children:"Lab Exercise 2: Multi-Threaded Agent"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Implement the MultiThreadedAgent example in ",(0,a.jsx)(n.code,{children:"agent_tutorial/multithreaded_agent.py"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Test the service interface:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# In one terminal, run the agent\nros2 run agent_tutorial multithreaded_agent\n\n# In another terminal, call the service\nros2 service call /agent/execute_task example_interfaces/srv/Trigger\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Monitor the status topic to see task completion:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"ros2 topic echo /agent/multi_status\n"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-3-configurable-agent",children:"Lab Exercise 3: Configurable Agent"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Implement the ConfigurableAgent example in ",(0,a.jsx)(n.code,{children:"agent_tutorial/configurable_agent.py"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Test parameter reconfiguration:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Run the agent\nros2 run agent_tutorial configurable_agent\n\n# Change parameters during runtime\nros2 param set /configurable_agent exploration_pattern grid\nros2 param set /configurable_agent movement_speed 0.7\nros2 param set /configurable_agent safety_distance 0.4\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Use rqt to visualize the parameter changes:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'rqt\n# Add the "Dynamic Reconfigure" plugin to change parameters graphically\n'})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"lab-exercise-4-agent-coordination",children:"Lab Exercise 4: Agent Coordination"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Create two agents that coordinate with each other:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:'A "scout" agent that explores and reports obstacles'}),"\n",(0,a.jsx)(n.li,{children:'A "follower" agent that follows the scout but avoids obstacles'}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Implement communication between agents using topics:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Scout publishes obstacle locations"}),"\n",(0,a.jsx)(n.li,{children:"Follower subscribes to obstacle locations and adjusts path accordingly"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Test the coordination in simulation (using Gazebo or a similar environment)"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"real-world-mapping",children:"Real-World Mapping"}),"\n",(0,a.jsx)(n.h3,{id:"industrial-applications",children:"Industrial Applications"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Warehouse Automation"}),": Multiple exploration agents coordinate to map warehouse layouts and optimize pick paths"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Quality Control"}),": Inspection agents use computer vision to identify defects and coordinate with corrective action agents"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Predictive Maintenance"}),": Monitoring agents continuously assess equipment health and coordinate with maintenance scheduling agents"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"service-robotics",children:"Service Robotics"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Hospital Robots"}),": Navigation agents coordinate with task execution agents to deliver supplies while avoiding obstacles and people"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Retail Assistants"}),": Customer service agents coordinate with inventory agents to provide accurate product location information"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cleaning Robots"}),": Coverage agents coordinate to ensure complete area cleaning while avoiding each other"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"research-platforms",children:"Research Platforms"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Swarm Robotics"}),": Simple agents follow local rules but exhibit complex emergent behaviors through coordination"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Human-Robot Interaction"}),": Social agents coordinate with perception and action agents to provide natural interaction"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Multi-Robot Systems"}),": Agents coordinate for complex tasks like search and rescue or construction"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"key-design-patterns",children:"Key Design Patterns"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Behavior Trees"}),": Hierarchical task execution for complex agent behaviors"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Finite State Machines"}),": Clear state transitions for predictable agent behavior"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Blackboard Architecture"}),": Shared knowledge repository for multi-agent coordination"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Reactive Systems"}),": Immediate response to environmental changes"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Deliberative Systems"}),": Planning-based decision making for complex tasks"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"Lesson 3 has covered the implementation of sophisticated Python agents using rclpy, focusing on state management, multi-threading, and configuration. We've explored how agents can embody the principles of Physical AI by bridging high-level intelligence with low-level physical control. The examples demonstrated various agent architectures, from simple exploration agents with state machines to complex multi-threaded systems with dynamic configuration. The lab exercises provide hands-on experience with creating and coordinating agents, while the real-world mapping section illustrates how these concepts apply to actual robotic applications. This foundation enables the development of intelligent, autonomous robotic systems capable of complex behaviors in physical environments."})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);